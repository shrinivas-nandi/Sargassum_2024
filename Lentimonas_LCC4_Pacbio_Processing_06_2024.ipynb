{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c1adac7",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "This script is being used to do a complete takedown of the Lentimonas LCC4 strain characterized by Sichert et al 2020 (https://www.nature.com/articles/s41564-020-0720-2)\n",
    "\n",
    "For this analysis we only focus on the transcriptome due to lack of transparency in the proteomic datasets. We use the **Lentimonas LCC4 Pacbio** genome for all analysis. We have uploaded all files associated with this genome to the box file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7547b2",
   "metadata": {},
   "source": [
    "# Step 1: Acquiring counts tables \n",
    "\n",
    "Due to the odd labelling method (Locus Tags) used by the authors, we proceeded to re-assess the transcriptomic reads uploaded to SRA (**#add number**). The overall process is \n",
    "\n",
    "1. Data download\n",
    "2. Read Clean up \n",
    "3. Genome indexing & Salmon quasi mapping\n",
    "4. Count tables \n",
    "\n",
    "The following code below is using bash terminal scripts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effe2747",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############STEP 1.1: Data download############################################################\n",
    "\n",
    "\n",
    "# data download \n",
    "# lets get the names of SRA files associated with project number \n",
    "module run Kingfisher_v0.4.1-rev1 kingfisher annotate --bioprojects <insert> -o <insert> -f tsv\n",
    "cut -f1 your_file.tsv > PRJ.txt\n",
    "\n",
    "\n",
    "# downloading all SRA files \n",
    "\n",
    "#!/bin/bash\n",
    "# Assuming your list is stored in a file named \"input_list.txt\"\n",
    "input_list=\"input_list.txt\"\n",
    "\n",
    "# Loop through each item in the list\n",
    "while IFS= read -r line; do\n",
    "    # Run the module command with the specified arguments\n",
    "    module run Kingfisher_v0.4.1-rev1 kingfisher get -r \"$line\" -m ena-ascp aws-http prefetch\n",
    "done < \"$input_list\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360e629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############STEP 1.2: Read Clean-Up ############################################################\n",
    "# Check qualtiy \n",
    "fastqc *.fastq\n",
    "mutliqc .\n",
    "\n",
    "# Clean up the fasta files (for single end reads)\n",
    "fastp -i <insert> -o <insert> --failed_out <insert>.txt --qualified_quality_phred 20 --unqualified_percent_limit 10 --thread 16\n",
    "\n",
    "# Re-Check qualtiy \n",
    "fastqc *.fastq\n",
    "mutliqc .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e994735",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############STEP 1.3: Genome Indexing & Quasi mapping ############################################################\n",
    "# Set the path to the directory containing the FASTQ files\n",
    "fastq_dir=\"\"\n",
    "\n",
    "# Set the index path\n",
    "index_path=\"\"\n",
    "\n",
    "# Set the output directory\n",
    "output_dir=\"\"\n",
    "\n",
    "# Loop over each FASTQ file in the directory\n",
    "for fastq_file in \"$fastq_dir\"/*.fastq; do\n",
    "    # Extract the filename without extension\n",
    "    filename=$(basename \"$fastq_file\" .fastq)\n",
    "    \n",
    "    # Run Salmon quantification for each FASTQ file\n",
    "    salmon quant --index \"$index_path\" \\\n",
    "                 --libType A \\\n",
    "                 --unmatedReads \"$fastq_file\" \\\n",
    "                 -p 30 \\\n",
    "                 --output \"$output_dir/${filename}_salmon_quant\"\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2332ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############STEP 1.4: Table Clean up ############################################################\n",
    "\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "# Set the directory containing the directories\n",
    "parent_directory=\"/path/to/parent_directory\"\n",
    "\n",
    "# Loop over each directory\n",
    "for directory in \"$parent_directory\"/*/; do\n",
    "    # Extract the directory name\n",
    "    dir_name=$(basename \"$directory\")\n",
    "    \n",
    "    # Check if quant.sf file exists in the directory\n",
    "    if [ -f \"$directory/quant.sf\" ]; then\n",
    "        # Rename quant.sf to directory_name.tsv\n",
    "        mv \"$directory/quant.sf\" \"$directory/$dir_name.tsv\"\n",
    "        echo \"Renamed quant.sf to $dir_name.tsv in $directory\"\n",
    "    else\n",
    "        echo \"quant.sf not found in $directory\"\n",
    "    fi\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc245943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main counts are gonna be in a file called quant.sf\n",
    "# Rename the files and move to somewhere better \n",
    "#!/bin/bash\n",
    "\n",
    "# Set the directory containing the directories\n",
    "parent_directory=\"/path/to/parent_directory\"\n",
    "\n",
    "# Loop over each directory\n",
    "for directory in \"$parent_directory\"/*/; do\n",
    "    # Extract the directory name\n",
    "    dir_name=$(basename \"$directory\")\n",
    "    \n",
    "    # Check if quant.sf file exists in the directory\n",
    "    if [ -f \"$directory/quant.sf\" ]; then\n",
    "        # Rename quant.sf to directory_name.tsv\n",
    "        mv \"$directory/quant.sf\" \"$directory/$dir_name.tsv\"\n",
    "        echo \"Renamed quant.sf to $dir_name.tsv in $directory\"\n",
    "    else\n",
    "        echo \"quant.sf not found in $directory\"\n",
    "    fi\n",
    "done\n",
    "\n",
    "# Script to move \n",
    "\n",
    "\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "# Define the target directory to move .sf files\n",
    "target_dir=\"new_directory\"\n",
    "\n",
    "# Create the target directory if it doesn't exist\n",
    "mkdir -p \"$target_dir\"\n",
    "\n",
    "# Iterate over directories starting with \"SRR\"\n",
    "for dir in SRR*/; do\n",
    "    # Check if directory contains .sf files\n",
    "    if [ -n \"$(find \"$dir\" -maxdepth 1 -type f -name '*.sf')\" ]; then\n",
    "        # Move all .sf files to the target directory\n",
    "        mv \"$dir\"*.sf \"$target_dir/\"\n",
    "        echo \"Moved .sf files from $dir to $target_dir/\"\n",
    "    else\n",
    "        echo \"No .sf files found in $dir\"\n",
    "    fi\n",
    "done\n",
    "\n",
    "find /scratch/shrinivas/Sargassum/Salmon_output/LCC4/quant_files -type f -name '*.tsv' -exec sh -c 'filename=$(basename \"{}\" .tsv); awk -v filename=\"$filename\" \"BEGIN {FS=OFS=\\\"\\t\\\"} NR==1 {gsub(/NumReads/, \\\"NumReads_\\\"filename); gsub(/TPM/, \\\"TPM_\\\"filename)} {print}\" \"{}\" > \"$filename\"_fixed_headers.tsv' \\;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88e50ad",
   "metadata": {},
   "source": [
    "At the end of this script we will obtain a counts table for each gene and its transcripts per million and the total number of reads. \n",
    "\n",
    "# Step 2: Annotating Reads\n",
    "The next step is to annotated the complete Lentimonas genome. We use different tools to try and get a holistic assessment of what the reads are. \n",
    "\n",
    "1. GhostKoala\n",
    "2. Diamond Blastp\n",
    "3. Eggnogg-Mapper\n",
    "4. InterProScan\n",
    "\n",
    "This section uses online tools and linux bash tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a1a023",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############STEP 2.1: GhostKoala ############################################################\n",
    "'''\n",
    "GhostKoala is an online tool link below \n",
    "https://www.kegg.jp/ghostkoala/\n",
    "Settings used: genus_prokaryotes + viruses\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864dcec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############STEP 2.2: Diamond Blastp ############################################################\n",
    "/home/timothy/programs/DIAMOND_v2.1.8/bin/diamond blastp --ultra-sensitive --iterate --max-target-seqs 1 --evalue 0.00001 --query /scratch/shrinivas/Sargassum/Genomes/Lentimonas_Genomes/Lentimonas_LCC4_Pacbio/protein.faa --db /scratch/databases/ncbi/2022_07/nr.dmnd --out Sargassum_pacbio_blast.tsv --threads 60 --compress 1 --outfmt 6 qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore qlen slen stitle staxids sscinames sphylums skingdoms sskingdoms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667005ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############STEP 2.3: Eggnogg-Mapper ############################################################\n",
    "/home/timothy/programs/eggnog-mapper-2.1.6/emapper.py -i <input> --cpu 48 --itype proteins -o <output> --data_dir /scratch/timothy/databases/eggnog-mapper-rel20211209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68a4340",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############STEP 2.4: InterProScanner ############################################################\n",
    "#!/usr/bin/env bash\n",
    "\n",
    "# Print all info to log file\n",
    "exec 1> \"${0}.log.$(date +%s)\" 2>&1\n",
    "\n",
    "#### Pre-run setup\n",
    "source ~/scripts/script_setup.sh\n",
    "set +eu; conda activate /home/timothy/miniconda3/envs/py38; set -eu\n",
    "\n",
    "INTERPROSCAN=\"/home/timothy/programs/my_interproscan/interproscan-5.53-87.0/interproscan.sh\"\n",
    "NCPUS=24\n",
    "\n",
    "#### Start Script\n",
    "FAA=\"protein.faa\"\n",
    "run_cmd \"${INTERPROSCAN} -dp --goterms --cpu ${NCPUS} --output-file-base ${FAA}.InterProScan --tempdir ${FAA}.InterProScan.temp --input ${FAA}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54652666",
   "metadata": {},
   "source": [
    "# Step 3: Differential Gene Expression\n",
    "\n",
    "For this section we used DESEQ2 on python to analyze the DGE of genes against the Mannose treatment. The authors of the paper us EdgeR, which is relatively lenient about replicates. The authors used LCC6 as a proxy replicate for LCC4 treatments.\n",
    "\n",
    "However, for this re-analysis we combine the timepoints of each treatment as a replicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2189551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages and libraries used \n",
    "#libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle as pkl\n",
    "\n",
    "from pydeseq2.dds import DeseqDataSet\n",
    "from pydeseq2.default_inference import DefaultInference\n",
    "from pydeseq2.ds import DeseqStats\n",
    "from pydeseq2.utils import load_example_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9be02d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/shrinivas/Desktop/Sargassum/PacBio_Transcriptome/Raw_counts_table.csv', index_col='Sample')\n",
    "# note: use NumReads for DESEQ2 analysis\n",
    "# Use TPM for DESEQ2 analysis\n",
    "\n",
    "metadata = pd.read_csv(r'/Users/shrinivas/Desktop/Sargassum/Transcriptome_LCC4/Meta_data_WGCNA.csv', index_col='Sample')\n",
    "transposed_data = df.T\n",
    "genes_to_keep = transposed_data.columns[transposed_data.sum(axis=0) >= 10] # minimal reads cut off\n",
    "transposed_data = transposed_data[genes_to_keep]\n",
    "transposed_data = transposed_data.fillna(0).astype(int).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636e5851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running DESEQ2\n",
    "dds = DeseqDataSet(\n",
    "    counts=transposed_data_sorted,\n",
    "    metadata=metadata_sorted,\n",
    "    design_factors=[\"Growth substrate\"], # based on metadata\n",
    "    refit_cooks=True)\n",
    "\n",
    "dds.deseq2()\n",
    "print(dds.varm[\"LFC\"]) # check to see if code processed correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed02610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing statistics. Log2FC, Wald t-test, and adjusted pvalues\n",
    "stat_res = DeseqStats(dds)\n",
    "stat_res_Y_vs_X = DeseqStats(dds, contrast=[\"Growth substrate\", \"iota\", \"Mannose\"])\n",
    "stat_res_Y_vs_X.summary()\n",
    "res2 = stat_res_Y_vs_X.results_df\n",
    "res2.to_csv('iota_vs_Mannose.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a252a4c0",
   "metadata": {},
   "source": [
    "# Step 4: Weighted Gene Co-Expression Analysis (On Going) \n",
    "\n",
    "This script is to build and assess modules of genes that are correlated with particular treatments. Further to build networks. \n",
    "\n",
    "While WGCNA has a python package, it is not as efficienty as the current R package. The code for the R package can be found at https://github.com/shrinivas-nandi/shrinivas-nandi/blob/main/R_files/WGCNA_Network.Rmd. \n",
    "\n",
    "**Note:** This is just a reference, only a couple of changes were made for this analysis, like file names etc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123ae7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "```{r}\n",
    "# packages used\n",
    "library(\"genefilter\")\n",
    "library(\"RColorBrewer\")\n",
    "library(\"WGCNA\")\n",
    "library(\"flashClust\")\n",
    "library(\"gridExtra\")\n",
    "library(\"ComplexHeatmap\")\n",
    "library(\"goseq\")\n",
    "library(\"dplyr\")\n",
    "library(\"clusterProfiler\")\n",
    "library(\"pheatmap\")\n",
    "library(\"magrittr\")\n",
    "library(\"dendsort\")\n",
    "library(\"ggplot2\")\n",
    "library('vegan')\n",
    "library('factoextra')\n",
    "library('ggfortify')\n",
    "library('naniar')\n",
    "library('cowplot')\n",
    "library(\"mixOmics\")\n",
    "library(\"tidyverse\")\n",
    "library(\"RVAideMemoire\")\n",
    "library(\"VennDiagram\")\n",
    "library(\"broom\")\n",
    "library(\"devtools\")\n",
    "library(\"tidyr\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7b344d",
   "metadata": {},
   "source": [
    "# Step 5: Downstream Analysis\n",
    "1. Selecting differentially expressed proteins (|FC| > 1.0 and adjpvalue < 0.05)\n",
    "2. Plotting out data \n",
    "\n",
    "**Note**: Reference code for plots can be found on https://github.com/shrinivas-nandi/shrinivas-nandi/tree/main/Plots\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
